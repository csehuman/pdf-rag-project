import time
from langchain_community.llms import Ollama
from utils.env_loader import load_env

base_url, model_name = load_env()

# Initialize LLM
llm = Ollama(model=model_name, base_url=base_url)

# Measure time
start_time = time.time()
response = llm("ì•ˆë…•í•˜ì„¸ìš”, 1+1ì€ ë¬´ì—‡ì¸ê°€ìš”?")
end_time = time.time()


print("\nğŸ“¦ LLM ì‘ë‹µ:", response)
print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
