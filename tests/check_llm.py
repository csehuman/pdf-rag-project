from dotenv import load_dotenv
import os
import time
from langchain_community.llms import Ollama

# Load .env
env_path = os.path.join(os.path.dirname(__file__), "..", ".env")
load_dotenv(dotenv_path=env_path)

base_url = os.getenv("OLLAMA_BASE_URL")
model_name = os.getenv("OLLAMA_MODEL_NAME")

print(f"[env] base_url: {base_url}")
print(f"[env] model_name: {model_name}")

if not base_url or not model_name:
    raise ValueError("í™˜ê²½ë³€ìˆ˜ë¥¼ .envì—ì„œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# Initialize LLM
llm = Ollama(model=model_name, base_url=base_url)

# Measure time
start_time = time.time()

response = llm("ì•ˆë…•í•˜ì„¸ìš”, 1+1ì€ ë¬´ì—‡ì¸ê°€ìš”?")

end_time = time.time()
elapsed = end_time - start_time

print("\nğŸ“¦ LLM ì‘ë‹µ:", response)
print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {elapsed:.2f}ì´ˆ")
